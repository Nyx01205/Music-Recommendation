{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-06T15:21:28.005270Z","iopub.execute_input":"2023-07-06T15:21:28.005674Z","iopub.status.idle":"2023-07-06T15:21:35.141044Z","shell.execute_reply.started":"2023-07-06T15:21:28.005641Z","shell.execute_reply":"2023-07-06T15:21:35.139566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sn\nimport skimage.io\nimport keras.backend as K\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout,BatchNormalization ,Activation\nfrom tensorflow.keras.models import Model, Sequential\nfrom keras.applications.nasnet import NASNetLarge\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2023-07-06T15:15:22.858926Z","iopub.execute_input":"2023-07-06T15:15:22.859791Z","iopub.status.idle":"2023-07-06T15:15:32.623829Z","shell.execute_reply.started":"2023-07-06T15:15:22.859755Z","shell.execute_reply":"2023-07-06T15:15:32.622823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale = 1./255,\n                                   validation_split = 0.2,\n                                  \n        rotation_range=5,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        shear_range=0.2,\n        #zoom_range=0.2,\n        horizontal_flip=True,\n        vertical_flip=True,\n        fill_mode='nearest')\n\nvalid_datagen = ImageDataGenerator(rescale = 1./255,\n                                  validation_split = 0.2)\n\ntest_datagen  = ImageDataGenerator(rescale = 1./255)\n                                  ","metadata":{"execution":{"iopub.status.busy":"2023-07-06T15:15:36.498986Z","iopub.execute_input":"2023-07-06T15:15:36.499850Z","iopub.status.idle":"2023-07-06T15:15:36.506199Z","shell.execute_reply.started":"2023-07-06T15:15:36.499814Z","shell.execute_reply":"2023-07-06T15:15:36.505180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset  = train_datagen.flow_from_directory(directory = '../input/fer2013/train',\n                                                   target_size = (48,48),\n                                                   class_mode = 'categorical',\n                                                   subset = 'training',\n                                                   batch_size = 64)","metadata":{"execution":{"iopub.status.busy":"2023-07-06T15:15:53.598906Z","iopub.execute_input":"2023-07-06T15:15:53.599277Z","iopub.status.idle":"2023-07-06T15:16:07.488528Z","shell.execute_reply.started":"2023-07-06T15:15:53.599247Z","shell.execute_reply":"2023-07-06T15:16:07.487526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_dataset = valid_datagen.flow_from_directory(directory = '../input/fer2013/train',\n                                                  target_size = (48,48),\n                                                  class_mode = 'categorical',\n                                                  subset = 'validation',\n                                                  batch_size = 64)","metadata":{"execution":{"iopub.status.busy":"2023-07-06T15:16:12.847367Z","iopub.execute_input":"2023-07-06T15:16:12.847746Z","iopub.status.idle":"2023-07-06T15:16:17.569736Z","shell.execute_reply.started":"2023-07-06T15:16:12.847717Z","shell.execute_reply":"2023-07-06T15:16:17.568827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = test_datagen.flow_from_directory(directory = '../input/fer2013/test',\n                                                  target_size = (48,48),\n                                                  class_mode = 'categorical',\n                                                  batch_size = 64)","metadata":{"execution":{"iopub.status.busy":"2023-07-06T15:18:01.181564Z","iopub.execute_input":"2023-07-06T15:18:01.181901Z","iopub.status.idle":"2023-07-06T15:18:03.816881Z","shell.execute_reply.started":"2023-07-06T15:18:01.181873Z","shell.execute_reply":"2023-07-06T15:18:03.815948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nbase_model = tf.keras.applications.VGG16(input_shape=(48,48,3),include_top=False,weights='imagenet')\n","metadata":{"execution":{"iopub.status.busy":"2023-07-06T15:37:02.753970Z","iopub.execute_input":"2023-07-06T15:37:02.754350Z","iopub.status.idle":"2023-07-06T15:37:03.521831Z","shell.execute_reply.started":"2023-07-06T15:37:02.754316Z","shell.execute_reply":"2023-07-06T15:37:03.520821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for layer in base_model.layers[:-4]:\n    layer.trainable=False","metadata":{"execution":{"iopub.status.busy":"2023-07-06T15:41:50.753278Z","iopub.execute_input":"2023-07-06T15:41:50.753687Z","iopub.status.idle":"2023-07-06T15:41:50.759326Z","shell.execute_reply.started":"2023-07-06T15:41:50.753656Z","shell.execute_reply":"2023-07-06T15:41:50.758421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=Sequential()\nmodel.add(base_model)\nmodel.add(Dropout(0.5))\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(32,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32,kernel_initializer='he_uniform'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dense(7,activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2023-07-06T15:42:48.453319Z","iopub.execute_input":"2023-07-06T15:42:48.453691Z","iopub.status.idle":"2023-07-06T15:42:48.686200Z","shell.execute_reply.started":"2023-07-06T15:42:48.453660Z","shell.execute_reply":"2023-07-06T15:42:48.685260Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-07-06T15:44:18.716028Z","iopub.execute_input":"2023-07-06T15:44:18.716403Z","iopub.status.idle":"2023-07-06T15:44:18.754846Z","shell.execute_reply.started":"2023-07-06T15:44:18.716370Z","shell.execute_reply":"2023-07-06T15:44:18.754105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nfrom IPython.display import Image\nplot_model(model, to_file='convnet.png', show_shapes=True,show_layer_names=True)\nImage(filename='convnet.png') ","metadata":{"execution":{"iopub.status.busy":"2023-07-06T15:44:38.632215Z","iopub.execute_input":"2023-07-06T15:44:38.632592Z","iopub.status.idle":"2023-07-06T15:44:38.926892Z","shell.execute_reply.started":"2023-07-06T15:44:38.632561Z","shell.execute_reply":"2023-07-06T15:44:38.925901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def f1_score(y_true, y_pred): #taken from old keras source code\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    recall = true_positives / (possible_positives + K.epsilon())\n    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n    return f1_val","metadata":{"execution":{"iopub.status.busy":"2023-07-06T15:44:56.495819Z","iopub.execute_input":"2023-07-06T15:44:56.496349Z","iopub.status.idle":"2023-07-06T15:44:56.502853Z","shell.execute_reply.started":"2023-07-06T15:44:56.496309Z","shell.execute_reply":"2023-07-06T15:44:56.501735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"METRICS = [\n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall'),  \n      tf.keras.metrics.AUC(name='auc'),\n        f1_score,\n]","metadata":{"execution":{"iopub.status.busy":"2023-07-06T15:45:11.367042Z","iopub.execute_input":"2023-07-06T15:45:11.367398Z","iopub.status.idle":"2023-07-06T15:45:11.399117Z","shell.execute_reply.started":"2023-07-06T15:45:11.367367Z","shell.execute_reply":"2023-07-06T15:45:11.398099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lrd = ReduceLROnPlateau(monitor = 'val_loss',patience = 20,verbose = 1,factor = 0.50, min_lr = 1e-10)\n\nmcp = ModelCheckpoint('model.h5')\n\nes = EarlyStopping(verbose=1, patience=20)","metadata":{"execution":{"iopub.status.busy":"2023-07-06T15:45:23.183389Z","iopub.execute_input":"2023-07-06T15:45:23.184286Z","iopub.status.idle":"2023-07-06T15:45:23.190005Z","shell.execute_reply.started":"2023-07-06T15:45:23.184238Z","shell.execute_reply":"2023-07-06T15:45:23.188887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=METRICS)","metadata":{"execution":{"iopub.status.busy":"2023-07-06T15:46:25.691649Z","iopub.execute_input":"2023-07-06T15:46:25.692005Z","iopub.status.idle":"2023-07-06T15:46:25.711639Z","shell.execute_reply.started":"2023-07-06T15:46:25.691977Z","shell.execute_reply":"2023-07-06T15:46:25.710721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=model.fit(train_dataset,validation_data=valid_dataset,epochs = 5,verbose = 1,callbacks=[lrd,mcp,es])","metadata":{"execution":{"iopub.status.busy":"2023-07-06T15:46:39.444772Z","iopub.execute_input":"2023-07-06T15:46:39.445276Z","iopub.status.idle":"2023-07-06T15:53:44.897804Z","shell.execute_reply.started":"2023-07-06T15:46:39.445234Z","shell.execute_reply":"2023-07-06T15:53:44.896772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Train_Val_Plot(acc,val_acc,loss,val_loss,auc,val_auc,precision,val_precision,f1,val_f1):\n    \n    fig, (ax1, ax2,ax3,ax4,ax5) = plt.subplots(1,5, figsize= (20,5))\n    fig.suptitle(\" MODEL'S METRICS VISUALIZATION \")\n\n    ax1.plot(range(1, len(acc) + 1), acc)\n    ax1.plot(range(1, len(val_acc) + 1), val_acc)\n    ax1.set_title('History of Accuracy')\n    ax1.set_xlabel('Epochs')\n    ax1.set_ylabel('Accuracy')\n    ax1.legend(['training', 'validation'])\n\n\n    ax2.plot(range(1, len(loss) + 1), loss)\n    ax2.plot(range(1, len(val_loss) + 1), val_loss)\n    ax2.set_title('History of Loss')\n    ax2.set_xlabel('Epochs')\n    ax2.set_ylabel('Loss')\n    ax2.legend(['training', 'validation'])\n    \n    ax3.plot(range(1, len(auc) + 1), auc)\n    ax3.plot(range(1, len(val_auc) + 1), val_auc)\n    ax3.set_title('History of AUC')\n    ax3.set_xlabel('Epochs')\n    ax3.set_ylabel('AUC')\n    ax3.legend(['training', 'validation'])\n    \n    ax4.plot(range(1, len(precision) + 1), precision)\n    ax4.plot(range(1, len(val_precision) + 1), val_precision)\n    ax4.set_title('History of Precision')\n    ax4.set_xlabel('Epochs')\n    ax4.set_ylabel('Precision')\n    ax4.legend(['training', 'validation'])\n    \n    ax5.plot(range(1, len(f1) + 1), f1)\n    ax5.plot(range(1, len(val_f1) + 1), val_f1)\n    ax5.set_title('History of F1-score')\n    ax5.set_xlabel('Epochs')\n    ax5.set_ylabel('F1 score')\n    ax5.legend(['training', 'validation'])\n\n\n    plt.show()\n    \n\nTrain_Val_Plot(history.history['accuracy'],history.history['val_accuracy'],\n               history.history['loss'],history.history['val_loss'],\n               history.history['auc'],history.history['val_auc'],\n               history.history['precision'],history.history['val_precision'],\n               history.history['f1_score'],history.history['val_f1_score']\n              )\n","metadata":{"execution":{"iopub.status.busy":"2023-07-06T15:56:32.078083Z","iopub.execute_input":"2023-07-06T15:56:32.078497Z","iopub.status.idle":"2023-07-06T15:56:33.219578Z","shell.execute_reply.started":"2023-07-06T15:56:32.078450Z","shell.execute_reply":"2023-07-06T15:56:33.218382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CLIENT_ID = \"\"\nCLIENT_SECRET = \"\"","metadata":{"execution":{"iopub.status.busy":"2023-07-11T07:27:15.948456Z","iopub.execute_input":"2023-07-11T07:27:15.948760Z","iopub.status.idle":"2023-07-11T07:27:15.960364Z","shell.execute_reply.started":"2023-07-11T07:27:15.948732Z","shell.execute_reply":"2023-07-11T07:27:15.959309Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"pip install tekore","metadata":{"execution":{"iopub.status.busy":"2023-07-11T07:27:41.576351Z","iopub.execute_input":"2023-07-11T07:27:41.576723Z","iopub.status.idle":"2023-07-11T07:27:54.805628Z","shell.execute_reply.started":"2023-07-11T07:27:41.576692Z","shell.execute_reply":"2023-07-11T07:27:54.804389Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting tekore\n  Downloading tekore-5.0.1-py3-none-any.whl (74 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.2/74.2 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting httpx<0.25,>=0.15 (from tekore)\n  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pydantic>=1.8 in /opt/conda/lib/python3.10/site-packages (from tekore) (1.10.7)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<0.25,>=0.15->tekore) (2023.5.7)\nCollecting httpcore<0.18.0,>=0.15.0 (from httpx<0.25,>=0.15->tekore)\n  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx<0.25,>=0.15->tekore) (3.4)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<0.25,>=0.15->tekore) (1.3.0)\nRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=1.8->tekore) (4.5.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx<0.25,>=0.15->tekore) (0.14.0)\nRequirement already satisfied: anyio<5.0,>=3.0 in /opt/conda/lib/python3.10/site-packages (from httpcore<0.18.0,>=0.15.0->httpx<0.25,>=0.15->tekore) (3.6.2)\nInstalling collected packages: httpcore, httpx, tekore\nSuccessfully installed httpcore-0.17.3 httpx-0.24.1 tekore-5.0.1\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install spotipy","metadata":{"execution":{"iopub.status.busy":"2023-07-11T07:28:10.593721Z","iopub.execute_input":"2023-07-11T07:28:10.594686Z","iopub.status.idle":"2023-07-11T07:28:22.703216Z","shell.execute_reply.started":"2023-07-11T07:28:10.594639Z","shell.execute_reply":"2023-07-11T07:28:22.701928Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Collecting spotipy\n  Downloading spotipy-2.23.0-py3-none-any.whl (29 kB)\nCollecting redis>=3.5.3 (from spotipy)\n  Downloading redis-4.6.0-py3-none-any.whl (241 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.1/241.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: requests>=2.25.0 in /opt/conda/lib/python3.10/site-packages (from spotipy) (2.28.2)\nRequirement already satisfied: six>=1.15.0 in /opt/conda/lib/python3.10/site-packages (from spotipy) (1.16.0)\nRequirement already satisfied: urllib3>=1.26.0 in /opt/conda/lib/python3.10/site-packages (from spotipy) (1.26.15)\nRequirement already satisfied: async-timeout>=4.0.2 in /opt/conda/lib/python3.10/site-packages (from redis>=3.5.3->spotipy) (4.0.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->spotipy) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->spotipy) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.25.0->spotipy) (2023.5.7)\nInstalling collected packages: redis, spotipy\nSuccessfully installed redis-4.6.0 spotipy-2.23.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport json\nimport re\nimport sys\nimport itertools\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier\nfrom tensorflow.keras import utils\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import cross_val_score, KFold, train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nimport spotipy\nfrom spotipy.oauth2 import SpotifyClientCredentials\nfrom spotipy.oauth2 import SpotifyOAuth\nimport spotipy.util as util\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-07-11T07:34:21.099825Z","iopub.execute_input":"2023-07-11T07:34:21.100572Z","iopub.status.idle":"2023-07-11T07:34:32.390358Z","shell.execute_reply.started":"2023-07-11T07:34:21.100533Z","shell.execute_reply":"2023-07-11T07:34:32.389373Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport json\nimport re\nimport sys\nimport itertools\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier\nfrom tensorflow.keras import utils\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import cross_val_score, KFold, train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import confusion_matrix, accuracy_score\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\nimport spotipy\nfrom spotipy.oauth2 import SpotifyClientCredentials\nfrom spotipy.oauth2 import SpotifyOAuth\nimport spotipy.util as util\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2023-07-11T07:45:30.258977Z","iopub.execute_input":"2023-07-11T07:45:30.259696Z","iopub.status.idle":"2023-07-11T07:45:30.268438Z","shell.execute_reply.started":"2023-07-11T07:45:30.259665Z","shell.execute_reply":"2023-07-11T07:45:30.267524Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import tekore as tk\ndef authorize():\n  app_token = tk.request_client_token(CLIENT_ID, CLIENT_SECRET)\n  return tk.Spotify(app_token)","metadata":{"execution":{"iopub.status.busy":"2023-07-11T07:45:46.390206Z","iopub.execute_input":"2023-07-11T07:45:46.390570Z","iopub.status.idle":"2023-07-11T07:45:46.861231Z","shell.execute_reply.started":"2023-07-11T07:45:46.390541Z","shell.execute_reply":"2023-07-11T07:45:46.860252Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport time\n\nsp = authorize()\n\n# Get all genres\ngenres = sp.recommendation_genre_seeds()\n\n# Set number of recommendations per genre\nn_recs = 10\n\n# Initiate a dictionary with all the information you want to crawl\ndata_dict = {\"id\":[], \"genre\":[], \"track_name\":[], \"artist_name\":[],\n             \"duration_ms\":[], \"danceability\":[], \"acousticness\":[], \"energy\":[], \"instrumentalness\":[],\n       \"liveness\":[], \"valence\":[], \"loudness\":[], \"speechiness\":[], \"tempo\":[]}\n\n\n# Get recs for every genre\nfor g in tqdm(genres):\n\n    # Get n recommendations\n    recs = sp.recommendations(genres = [g], limit = n_recs)\n    # json-like string to dict\n    recs = eval(recs.json().replace(\"null\", \"-999\").replace(\"false\", \"False\").replace(\"true\", \"True\"))[\"tracks\"]\n\n    # Crawl data from each track\n    for track in recs:\n        # ID and Genre\n        data_dict[\"id\"].append(track[\"id\"])\n        data_dict[\"genre\"].append(g)\n        # Metadata\n        track_meta = sp.track(track[\"id\"])\n        data_dict[\"track_name\"].append(track_meta.name)\n        data_dict[\"artist_name\"].append(track_meta.album.artists[0].name)\n\n        track_features = sp.track_audio_features(track[\"id\"])\n        data_dict[\"valence\"].append(track_features.valence)\n        data_dict[\"energy\"].append(track_features.energy)\n        data_dict[\"duration_ms\"].append(track_features.duration_ms)\n        data_dict[\"danceability\"].append(track_features.danceability)\n        data_dict[\"acousticness\"].append(track_features.acousticness)\n        data_dict[\"instrumentalness\"].append(track_features.instrumentalness)\n        data_dict[\"liveness\"].append(track_features.liveness)\n        data_dict[\"loudness\"].append(track_features.loudness)\n        data_dict[\"speechiness\"].append(track_features.speechiness)\n        data_dict[\"tempo\"].append(track_features.tempo)\n\n        # Wait 0.2 seconds per track so that the api doesnt overheat\n        time.sleep(0.2)\n\n\nspotify_df = pd.DataFrame(data_dict)\n\n# Drop duplicates\ndf.drop_duplicates(subset = \"id\", keep = \"first\", inplace = True)\ndf.to_csv(\"valence_arousal_dataset.csv\", index = False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mood_prep = spotify_df[['duration_ms', 'danceability', 'acousticness', 'energy', 'instrumentalness',\n       'liveness', 'valence', 'loudness', 'speechiness', 'tempo']]\ncol_features = mood_prep.columns[:]\nmood_trans = MinMaxScaler().fit_transform(mood_prep[col_features])\nmood_trans_np = np.array(mood_prep[col_features])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('data_moods.csv')\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cl_features = df.columns[6:-3]\nX= MinMaxScaler().fit_transform(df[cl_features])\nX2 = np.array(df[cl_features])\nY = df['mood']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cl_features\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = LabelEncoder()\nencoder.fit(Y)\nencoded_y = encoder.transform(Y)\n\n\ndummy_y = utils.to_categorical(encoded_y)\n\nX_train,X_test,Y_train,Y_test = train_test_split(X,encoded_y,test_size=0.2,random_state=15)\n\ntarget = pd.DataFrame({'mood':df['mood'].tolist(),'encode':encoded_y}).drop_duplicates().sort_values(['encode'],ascending=True)\ntarget","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def base_model():\n    model = Sequential()\n    model.add(Dense(8,input_dim=10,activation='relu'))\n    model.add(Dense(4,activation='softmax'))\n    model.compile(loss='categorical_crossentropy',optimizer='adam',\n                 metrics=['accuracy'])\n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimator = KerasClassifier(build_fn=base_model,epochs=300,batch_size=200,verbose=0)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluate the model using KFold cross validation\nkfold = KFold(n_splits=10,shuffle=True)\nresults = cross_val_score(estimator,X,encoded_y,cv=kfold)\nprint(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100,results.std()*100)) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimator.fit(X_train,Y_train)\ny_preds = estimator.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip = Pipeline([('minmaxscaler',MinMaxScaler()),('keras',KerasClassifier(build_fn=base_model,epochs=300, batch_size=200,verbose=0))])\npip.fit(X2,encoded_y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict_mood(preds):\n\n    preds_features = np.array(preds[:]).reshape(-1,1).T\n    results = pip.predict(preds_features)\n    mood = np.array(target['mood'][target['encode']==int(results)])\n    return str(mood[0])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = []\n\nfor i in range(len(mood_trans_np)):\n  res.append(predict_mood(mood_trans_np[i]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spotify_df.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(res))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spotify_df['Mood'] = np.resize(res,len(spotify_df))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spotify_df.to_csv('kaggleMusicMoodFinal.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spotify_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"MUSIC RECOMMENDER\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport json\nimport re\nimport sys\nimport itertools\n\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.preprocessing import MinMaxScaler\nfrom skimage import io\nimport matplotlib.pyplot as plt\n\n\nimport spotipy\nfrom spotipy.oauth2 import SpotifyClientCredentials\nfrom spotipy.oauth2 import SpotifyOAuth\nimport spotipy.util as util\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('kaggleMusicMoodFinal.csv')\nspotify_df = df.copy()\nspotify_df.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def ChooseDataset(x):\n    if x == \"Disgust\":\n        return spotify_df[spotify_df['Mood'].isin(['Energetic', 'Happy', 'Calm'])]\n    if x == \"Angry\":\n        return spotify_df[spotify_df['Mood'].isin(['Energetic', 'Calm'])]\n    if x == \"Fear\":\n        return spotify_df[spotify_df['Mood'].isin(['Happy', 'Calm'])]\n    if x == \"Happy\":\n        return spotify_df[spotify_df['Mood'].isin(['Sad', 'Happy', 'Calm'])]\n    if x == \"Sad\":\n        return spotify_df[spotify_df['Mood'].isin(['Sad', 'Happy', 'Calm'])]\n    if x == \"Surprise\":\n        return spotify_df[spotify_df['Mood'].isin(['Energetic', 'Happy', 'Sad'])]\n    return spotify_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"O_df = ChooseDataset(\"Angry\")\nO_df[['track_name','artist_name']]","metadata":{},"execution_count":null,"outputs":[]}]}